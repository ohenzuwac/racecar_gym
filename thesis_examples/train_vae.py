
from torch.optim import Adam
from torch import nn
import torch
from torch.utils.data import DataLoader
from attention_vae import AttentionVAE
from pandas_dataset import CustomDataset
import matplotlib.pyplot as plt

import numpy as np

from tqdm import tqdm
import pandas as pd


def loss_function(x, x_hat, mean, log_var):
    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')
    KLD  = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())
    return reproduction_loss + KLD

def l2_loss(x, x_hat):
    sq_error = (x-x_hat)**2
    sq_error = sq_error.sum(-1).sum(-1).sum(-1)
    return sq_error



def train():

    # Model Hyperparameters

    dataset_path = '~/datasets'

    cuda = True
    DEVICE = torch.device("cuda" if cuda else "cpu")


    #todo: overwrite dims
    batch_size = 1
    x_dim = 784
    hidden_dim = 540
    latent_dim = 2

    num_csvs = 2
    df_list = []
    for i in range(num_csvs):
        df = pd.read_csv(f"csv_files/0425/Episode{i}")
        df_list.append(df)
    train_dataset = CustomDataset(df_list)
    test_dataset = CustomDataset(df_list)

    model = AttentionVAE(sequence_length=train_dataset.sequence_length,
                         num_agents=train_dataset.num_agents,
                         latent_dim=latent_dim,
                         embedding_dim=hidden_dim)

    lr = 1e-3

    epochs = 1

    kwargs = {'num_workers': 1, 'pin_memory': True}

    # TODO


    # TRAJECTORY format should be [batch_size, num_agents, timesteps, spatial_dim (=2)]
    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)
    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, **kwargs)
    BCE_loss = nn.BCELoss()

    optimizer = Adam(model.parameters(), lr=lr)

    print("Start training VAE...")
    model.train()

    for epoch in range(epochs):
        overall_loss = 0
        for batch_idx, x in enumerate(train_loader):

            #print("x ", x.size(), x)

            optimizer.zero_grad()

            x_hat, mean, log_var = model(x)
            loss = l2_loss(x, x_hat).mean()

            overall_loss += loss.item()

            loss.backward()
            optimizer.step()

        batch_idx += 1

        print("\tEpoch", epoch + 1, "complete!", "\tAverage Loss: ", overall_loss / (batch_idx * batch_size))

    print("Finish!!")

    return model, test_loader


# x is the sample trajectories or original trajectories in the format generated by tensor's dataloader
def plot_traj(x,model):
    x_vals = []
    y_vals = []

    for i in range(model.num_agents):
        print("this is a matrix!")
        (print(x[0,0])) #--> gets the first matrix
        #print(x[0,0,1]) #--> gets the first row
        #print(x[0,0,:,0]) # --> gets the all rows in the first col

        x_vals.append(x[0,i,:,0].detach().numpy()) #append x and y trajectories for each agent
        y_vals.append(x[0,i,:,1].detach().numpy())

        #print(x_vals[0])

    #print(x_vals[0].numpy().size)
    #x_vals[0] = x_vals[0].numpy()
    #y_vals[0] = y_vals[0].numpy()
    plt.plot(x_vals[0], y_vals[0],x_vals[1],y_vals[1],x_vals[2],y_vals[2],x_vals[3],y_vals[3])
    plt.xlabel("x position")
    plt.ylabel("y position")
    plt.title("Ground Truth Trajectories for Agents")
    plt.legend(["Agent A", "Agent B", "Agent C", "Agent D"], loc = "lower right")
    plt.show()

    return x_vals,y_vals









if __name__ == "__main__":
    model, test_loader = train()
    sample = model.sample(1,torch.device('cpu'))
    for batch_idx, x in enumerate(test_loader):
        result, mu, log_var = model(x)

    sample = sample.reshape(-1, model.num_agents, model.sequence_length, 3)

    #plot original trajectories
    plot_traj(x,model)

    #gather the relevant information (x,y values for now)




